# Learning Not to Learn: Training Deep Neural Networks with Biased Data

## Abstract
We propose a novel regularization algorithm to train
deep neural networks, in which data at training time is
severely biased. Since a neural network efficiently learns
data distribution, a network is likely to learn the bias information
to categorize input data. It leads to poor performance
at test time, if the bias is, in fact, irrelevant to the
categorization. In this paper, we formulate a regularization
loss based on mutual information between feature embedding
and bias. Based on the idea of minimizing this mutual
information, we propose an iterative algorithm to unlearn
the bias information. We employ an additional network to
predict the bias distribution and train the network adversarially
against the feature embedding network. At the end of
learning, the bias prediction network is not able to predict
the bias not because it is poorly trained, but because the
feature embedding network successfully unlearns the bias
information. We also demonstrate quantitative and qualitative
experimental results which show that our algorithm
effectively removes the bias information from feature embedding.

## Summary in russian
Авторы обучают сеть на данных содержащих биас так, чтобы она робастно работала на данных без биаса. Предполагается, что биас при этом заранее известен и для него есть отдельный лейбл.

Подход демонстрируется на трех датасетах:
* раскрашенный MNIST, где каждой цифре соответствует свой цвет в train-части, и рандомно назначен в test-части;
* Dogs and Cats, где для одного класса выбраны животные темного окраса, а для второго светлого;
* IMDB-Face: здесь лейблами выступают пол и возраст для лиц с imdb.com. В обучающей части, данные опять же разделены так, что одному из полов соотвествует возраст 0-29, а второму 40+.

Решение вдохновлено InfoGAN и выглядит так. Вся сеть делится на три части:
* f(x) -- экстрактор фич;
* g -- классификатор для основной задачи;
* h -- классификатор для биаса, моделирующий P(bias(x)|f(x)).

Делается два лосса:
* кроссэнтропия для g(f(x)) и лейблов;
* и кроссэнтропия для h(f(x)) и лейблов для биаса.

От второго лосса градиенты через h-часть проходят прямо, а перед f-частью сети разворачиваются. Всё учится end-to-end. В итоге, сначала хорошо учится h-сеть, а потом, когда из эмбеддинга пропадает информация о биасе, учится g-сеть. Причем, эмбеддинг при этом получается не зависящий от биаса.

Архитектура модели была следующей: за g(f(x)) брался ResNet-18 (с imagenet-весами), где первые два res-блока были f, а последние два g. Роль h-сети играли два conv-слоя (c BN и ReLU) для MNIST и Dogs&Cats, и один fc-слой для age/gender классификации. Всё тренировалось SGD с моментом 0.9 и lr 0.001 c l2-регуляризацией для всех параметров.

Получившаяся модель сравнивается с бейзлайном на валидации и данных с противоположным биасом. Предложенная модель лучше и там и там (особенно, конечно, на контр-данных). Но прилично докидывает только на первых двух датасетах. Для пола-возраста результат получается всё равно очень слабый. Авторы пишут, что, возможно, это связано с тем что пол и возраст "коррелируют", а значит убирая информацию об одном, мешаешь предсказывать другое. Результаты на контр-данных, получаются прямо сильно хуже (Table 2).
